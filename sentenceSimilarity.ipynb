{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = [\"It's a 2014 model, too old for me\",\n",
    "\"Hi, I'm selling my 2014 Toyota Prius.\",\n",
    "\"It has only 65k miles. \",\n",
    "\"It has Backup camera, Bluetooth, CD, AUX, Keyless Go.\",\n",
    "\"There was no engine or transmission damage. \",\n",
    "\"Very clean inside\",\n",
    "\"never smoke.\"\n",
    "\"Well maintained.\",\n",
    "\"Oil change every 5k miles with synthetic Toyota Original Oil. \",\n",
    "\"Registered until February 2019. Title on hands. \",\n",
    "\"It lost its clean title status due to rear bumper hit.\", \n",
    "\"Small scratch on the right side. \",\n",
    "\"I'm the second owner and had no any problem with it. \",\n",
    "\"The car is great, 50+ MPG. \",\n",
    "\"Will run 100k miles more easily. Call me or better text at any time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SentenceTransformer(\"bert-base-nli-mean-tokens\")\n",
    "# sentences_vec = model.encode(description)\n",
    "def count_vector(data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    count_vectorizer.fit(data)\n",
    "    vect = count_vectorizer.transform(data)\n",
    "    return vect\n",
    "\n",
    "def remove_number(text):\n",
    "    num = re.compile(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*')\n",
    "    return num.sub(r'NUMBER', text)\n",
    "\n",
    "def text_stemmer(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    text = ' '.join(stemmer.stem(token) for token in word_tokenize(text))\n",
    "    return text\n",
    "\n",
    "def remove_all_punct(text):\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "def text_tokenize(text):\n",
    "    text = word_tokenize(text)\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    return text\n",
    "\n",
    "def text_preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = remove_all_punct(text)\n",
    "    # text = remove_number(text)\n",
    "    text = text_stemmer(text)\n",
    "    text = text_tokenize(text)\n",
    "    text = count_vector(text)\n",
    "    print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = input(\"Enter first string: \").lower()\n",
    "# Y = input(\"Enter second string: \").lower()\n",
    "input =\"It's only gone 65k miles\"\n",
    "description =\"Hi, I'm selling my 2014 Toyota Prius. It has only 65k miles. It has Backup camera, Bluetooth, CD, AUX, Keyless Go. There was no engine or transmission damage. Very clean inside, never smoke. Well maintained. Oil change every 5k miles with synthetic Toyota Original Oil. Registered until February 2019. Title on hands. It lost its clean title status due to rear bumper hit. Small scratch on the right side. I'm the second owner and had no any problem with it. The car is great, 50+ MPG. Will run 100k miles more easily. Call me or better text at any time\"\n",
    "\n",
    "def cosineSimilarity(input, description):\n",
    "\tinput, description = remove_all_punct(input), remove_all_punct(description)\n",
    "\tinput, description = text_stemmer(input), text_stemmer(description)\n",
    "\tinput, description = text_tokenize(input), text_tokenize(description)\n",
    "\n",
    "\tl1 = []\n",
    "\tl2 = []\n",
    "\t# form a set containing keywords of both strings\n",
    "\trvector = input.union(description)\n",
    "\tfor w in rvector:\n",
    "\t\tif w in input: l1.append(1) # create a vector\n",
    "\t\telse: l1.append(0)\n",
    "\t\tif w in description: l2.append(1)\n",
    "\t\telse: l2.append(0)\n",
    "\tc = 0\n",
    "\n",
    "\t# cosine formula\n",
    "\tfor i in range(len(rvector)):\n",
    "\t\t\tc+= l1[i]*l2[i]\n",
    "\tcosine = c / float((sum(l1)*sum(l2))**0.5)\n",
    "\tprint(\"similarity: \", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'union'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-d4ebce4c22e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(jaccard_score([sentences_vec[0]], [sentences_vec[1]]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(cosine_similarity([sentences_vec[0]], [sentences_vec[1]]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcosineSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-79-905fc69930c2>\u001b[0m in \u001b[0;36mcosineSimilarity\u001b[0;34m(input, description)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# form a set containing keywords of both strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mrvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrvector\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# create a vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'union'"
     ]
    }
   ],
   "source": [
    "# ic_model.text_preprocess(\"No. That is too much for a 2014 Toyota prius\")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_score\n",
    "# print(jaccard_score([sentences_vec[0]], [sentences_vec[1]]))\n",
    "# print(cosine_similarity([sentences_vec[0]], [sentences_vec[1]]))\n",
    "# cosineSimilarity(input, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'love', 'horror', 'I', 'movies'} {'Lights', 'movie', 'horror'}\n",
      "[0, 0, 1, 1, 1, 1] [1, 1, 0, 0, 1, 0]\n",
      "similarity:  0.2886751345948129\n"
     ]
    }
   ],
   "source": [
    "# X = input(\"Enter first string: \").lower()\n",
    "# Y = input(\"Enter second string: \").lower()\n",
    "X =\"I love horror movies\"\n",
    "Y =\"Lights out is a horror movie\"\n",
    "  \n",
    "# tokenization\n",
    "X_list = word_tokenize(X) \n",
    "Y_list = word_tokenize(Y)\n",
    "  \n",
    "# sw contains the list of stopwords\n",
    "sw = stopwords.words('english') \n",
    "l1 =[];l2 =[]\n",
    "  \n",
    "# remove stop words from the string\n",
    "X_set = {w for w in X_list if not w in sw} \n",
    "Y_set = {w for w in Y_list if not w in sw}\n",
    "\n",
    "print(X_set, Y_set)\n",
    "  \n",
    "# form a set containing keywords of both strings \n",
    "rvector = X_set.union(Y_set) \n",
    "for w in rvector:\n",
    "    if w in X_set: l1.append(1) # create a vector\n",
    "    else: l1.append(0)\n",
    "    if w in Y_set: l2.append(1)\n",
    "    else: l2.append(0)\n",
    "c = 0\n",
    "\n",
    "print(l1, l2)\n",
    "  \n",
    "# cosine formula \n",
    "for i in range(len(rvector)):\n",
    "        c+= l1[i]*l2[i]\n",
    "cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
    "print(\"similarity: \", cosine)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a0abec15e4fb4cfa094c15e2c94b64d68358a12f71cdd1f46d2cd763cfd2a99"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
